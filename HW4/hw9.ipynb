{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "load(\"mnist.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast 2D image into 1D array\n",
    "dim(x_test) <- c(60000, 28 * 28)\n",
    "dim(x_train) <- c(10000, 28 * 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do PCA to the images in order to reduce the dimension of our input data. This preprocessing step would greatly save the time of SVM training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Importance of components:\n",
       "                            Comp.1       Comp.2       Comp.3       Comp.4\n",
       "Standard deviation     587.6084300 509.17881566 459.36501954 431.80500000\n",
       "Proportion of Variance   0.1004766   0.07544487   0.06140516   0.05425807\n",
       "Cumulative Proportion    0.1004766   0.17592150   0.23732666   0.29158474\n",
       "                             Comp.5       Comp.6       Comp.7       Comp.8\n",
       "Standard deviation     415.80851801 382.00061099 337.33511356 318.41074319\n",
       "Proportion of Variance   0.05031249   0.04246363   0.03311404   0.02950288\n",
       "Cumulative Proportion    0.34189722   0.38436086   0.41747490   0.44697778\n",
       "                             Comp.9      Comp.10      Comp.11      Comp.12\n",
       "Standard deviation     306.28483042 279.79264052 270.79608231 268.32961726\n",
       "Proportion of Variance   0.02729858   0.02278041   0.02133899   0.02095204\n",
       "Cumulative Proportion    0.47427636   0.49705677   0.51839576   0.53934779\n",
       "                            Comp.13      Comp.14      Comp.15      Comp.16\n",
       "Standard deviation     243.53593721 240.68724240 232.72564468 226.62743643\n",
       "Proportion of Variance   0.01725898   0.01685758   0.01576077   0.01494562\n",
       "Cumulative Proportion    0.55660678   0.57346435   0.58922513   0.60417075\n",
       "                            Comp.17      Comp.18      Comp.19     Comp.20\n",
       "Standard deviation     211.56577773 209.60436266 201.38090388 198.6475009\n",
       "Proportion of Variance   0.01302506   0.01278467   0.01180118   0.0114830\n",
       "Cumulative Proportion    0.61719581   0.62998049   0.64178167   0.6532647\n",
       "                           Comp.21      Comp.22      Comp.23      Comp.24\n",
       "Standard deviation     191.4333231 187.87903248 1.834870e+02 1.760463e+02\n",
       "Proportion of Variance   0.0106641   0.01027178 9.797149e-03 9.018673e-03\n",
       "Cumulative Proportion    0.6639288   0.67420055 6.839977e-01 6.930164e-01\n",
       "                            Comp.25      Comp.26      Comp.27      Comp.28\n",
       "Standard deviation     1.747102e+02 1.685373e+02 1.657795e+02 1.622273e+02\n",
       "Proportion of Variance 8.882306e-03 8.265726e-03 7.997432e-03 7.658379e-03\n",
       "Cumulative Proportion  7.018987e-01 7.101644e-01 7.181618e-01 7.258202e-01\n",
       "                            Comp.29      Comp.30      Comp.31      Comp.32\n",
       "Standard deviation     1.570256e+02 1.536791e+02 1.493572e+02 146.80617253\n",
       "Proportion of Variance 7.175137e-03 6.872557e-03 6.491443e-03   0.00627159\n",
       "Cumulative Proportion  7.329953e-01 7.398679e-01 7.463593e-01   0.75263094\n",
       "                            Comp.33      Comp.34      Comp.35      Comp.36\n",
       "Standard deviation     1.424250e+02 141.39271304 1.368199e+02 1.364322e+02\n",
       "Proportion of Variance 5.902844e-03   0.00581759 5.447376e-03 5.416552e-03\n",
       "Cumulative Proportion  7.585338e-01   0.76435137 7.697987e-01 7.752153e-01\n",
       "                            Comp.37      Comp.38      Comp.39      Comp.40\n",
       "Standard deviation     1.320272e+02 128.58272284 1.257514e+02 1.245648e+02\n",
       "Proportion of Variance 5.072425e-03   0.00481121 4.601661e-03 4.515228e-03\n",
       "Cumulative Proportion  7.802877e-01   0.78509893 7.897006e-01 7.942158e-01\n",
       "                            Comp.41      Comp.42      Comp.43      Comp.44\n",
       "Standard deviation     122.54895496 120.76045771 119.12737074 1.157130e+02\n",
       "Proportion of Variance   0.00437027   0.00424364   0.00412964 3.896311e-03\n",
       "Cumulative Proportion    0.79858609   0.80282973   0.80695937 8.108557e-01\n",
       "                            Comp.45      Comp.46      Comp.47      Comp.48\n",
       "Standard deviation     1.140092e+02 1.128305e+02 1.109607e+02 1.067691e+02\n",
       "Proportion of Variance 3.782411e-03 3.704607e-03 3.582843e-03 3.317264e-03\n",
       "Cumulative Proportion  8.146381e-01 8.183427e-01 8.219255e-01 8.252428e-01\n",
       "                            Comp.49      Comp.50      Comp.51      Comp.52\n",
       "Standard deviation     1.059758e+02 103.51964393 1.022217e+02 1.011686e+02\n",
       "Proportion of Variance 3.268152e-03   0.00311842 3.040711e-03 2.978385e-03\n",
       "Cumulative Proportion  8.285110e-01   0.83162938 8.346701e-01 8.376485e-01\n",
       "                            Comp.53      Comp.54      Comp.55     Comp.56\n",
       "Standard deviation     99.567645426 97.864521466 96.862053645 95.06144767\n",
       "Proportion of Variance  0.002884865  0.002787017  0.002730212  0.00262965\n",
       "Cumulative Proportion   0.840533341  0.843320358  0.846050570  0.84868022\n",
       "                            Comp.57      Comp.58      Comp.59      Comp.60\n",
       "Standard deviation     93.603888322 93.245482693 91.673090365 91.088790789\n",
       "Proportion of Variance  0.002549628  0.002530141  0.002445529  0.002414454\n",
       "Cumulative Proportion   0.851229848  0.853759988  0.856205517  0.858619971\n",
       "                            Comp.61      Comp.62     Comp.63      Comp.64\n",
       "Standard deviation     89.742909282 89.546569416 87.55421282 86.061643684\n",
       "Proportion of Variance  0.002343632  0.002333388  0.00223071  0.002155303\n",
       "Cumulative Proportion   0.860963603  0.863296991  0.86552770  0.867683004\n",
       "                            Comp.65      Comp.66     Comp.67      Comp.68\n",
       "Standard deviation     84.711821929 83.384283211 82.80392392 80.506437222\n",
       "Proportion of Variance  0.002088224  0.002023287  0.00199522  0.001886037\n",
       "Cumulative Proportion   0.869771228  0.871794514  0.87378973  0.875675772\n",
       "                            Comp.69      Comp.70      Comp.71      Comp.72\n",
       "Standard deviation     80.205188885 79.877699133 78.777127514 77.408738420\n",
       "Proportion of Variance  0.001871949  0.001856693  0.001805882  0.001743689\n",
       "Cumulative Proportion   0.877547721  0.879404414  0.881210296  0.882953985\n",
       "                           Comp.73      Comp.74      Comp.75      Comp.76\n",
       "Standard deviation     76.53460522 75.146560077 75.087052076 73.540503509\n",
       "Proportion of Variance  0.00170453  0.001643264  0.001640662  0.001573774\n",
       "Cumulative Proportion   0.88465851  0.886301779  0.887942441  0.889516214\n",
       "                            Comp.77      Comp.78      Comp.79      Comp.80\n",
       "Standard deviation     72.879114737 71.384689846 70.113590206 69.142714532\n",
       "Proportion of Variance  0.001545593  0.001482857  0.001430518  0.001391175\n",
       "Cumulative Proportion   0.891061807  0.892544664  0.893975183  0.895366358\n",
       "                            Comp.81      Comp.82      Comp.83      Comp.84\n",
       "Standard deviation     68.805294771 67.905362042 67.303480524 67.153455247\n",
       "Proportion of Variance  0.001377631  0.001341829  0.001318148  0.001312278\n",
       "Cumulative Proportion   0.896743989  0.898085818  0.899403965  0.900716243\n",
       "                            Comp.85      Comp.86      Comp.87      Comp.88\n",
       "Standard deviation     66.715222629 65.559657384 64.899863385 64.644693465\n",
       "Proportion of Variance  0.001295206  0.001250727  0.001225679  0.001216059\n",
       "Cumulative Proportion   0.902011449  0.903262176  0.904487854  0.905703914\n",
       "                           Comp.89      Comp.90      Comp.91      Comp.92\n",
       "Standard deviation     63.43113511 62.934231776 61.634572252 61.451492723\n",
       "Proportion of Variance  0.00117083  0.001152558  0.001105447  0.001098889\n",
       "Cumulative Proportion   0.90687474  0.908027303  0.909132749  0.910231639\n",
       "                            Comp.93      Comp.94      Comp.95      Comp.96\n",
       "Standard deviation     60.825512153 60.701627959 59.973276948 59.222946540\n",
       "Proportion of Variance  0.001076615  0.001072234  0.001046658  0.001020632\n",
       "Cumulative Proportion   0.911308254  0.912380488  0.913427146  0.914447778\n",
       "                            Comp.97      Comp.98      Comp.99     Comp.100\n",
       "Standard deviation     58.700336474 5.837530e+01 5.757568e+01 5.709629e+01\n",
       "Proportion of Variance  0.001002698 9.916246e-04 9.646443e-04 9.486474e-04\n",
       "Cumulative Proportion   0.915450476 9.164421e-01 9.174067e-01 9.183554e-01\n",
       "                           Comp.101     Comp.102     Comp.103     Comp.104\n",
       "Standard deviation     5.667970e+01 5.637951e+01 5.503597e+01 5.460055e+01\n",
       "Proportion of Variance 9.348548e-04 9.249785e-04 8.814189e-04 8.675271e-04\n",
       "Cumulative Proportion  9.192902e-01 9.202152e-01 9.210966e-01 9.219642e-01\n",
       "                           Comp.105     Comp.106     Comp.107     Comp.108\n",
       "Standard deviation     54.116165859 5.407460e+01 53.739879540 53.075626343\n",
       "Proportion of Variance  0.000852203 8.508943e-04  0.000840393  0.000819746\n",
       "Cumulative Proportion   0.922816374 9.236673e-01  0.924507662  0.925327408\n",
       "                           Comp.109     Comp.110     Comp.111     Comp.112\n",
       "Standard deviation     5.260028e+01 51.839167187 5.135283e+01 5.111906e+01\n",
       "Proportion of Variance 8.051284e-04  0.000781997 7.673929e-04 7.604222e-04\n",
       "Cumulative Proportion  9.261325e-01  0.926914533 9.276819e-01 9.284423e-01\n",
       "                           Comp.113     Comp.114     Comp.115     Comp.116\n",
       "Standard deviation     5.087197e+01 5.031749e+01 4.997998e+01 4.956246e+01\n",
       "Proportion of Variance 7.530887e-04 7.367617e-04 7.269109e-04 7.148167e-04\n",
       "Cumulative Proportion  9.291954e-01 9.299322e-01 9.306591e-01 9.313739e-01\n",
       "                           Comp.117     Comp.118     Comp.119     Comp.120\n",
       "Standard deviation     4.941208e+01 4.907316e+01 4.861570e+01 4.794169e+01\n",
       "Proportion of Variance 7.104857e-04 7.007727e-04 6.877683e-04 6.688298e-04\n",
       "Cumulative Proportion  9.320844e-01 9.327852e-01 9.334730e-01 9.341418e-01\n",
       "                           Comp.121     Comp.122     Comp.123     Comp.124\n",
       "Standard deviation     4.778360e+01 4.761509e+01 4.740091e+01 4.704361e+01\n",
       "Proportion of Variance 6.644264e-04 6.597483e-04 6.538262e-04 6.440065e-04\n",
       "Cumulative Proportion  9.348062e-01 9.354660e-01 9.361198e-01 9.367638e-01\n",
       "                           Comp.125     Comp.126     Comp.127     Comp.128\n",
       "Standard deviation     4.668533e+01 4.625626e+01 45.964374506 4.569567e+01\n",
       "Proportion of Variance 6.342345e-04 6.226299e-04  0.000614797 6.076299e-04\n",
       "Cumulative Proportion  9.373980e-01 9.380207e-01  0.938635451 9.392431e-01\n",
       "                           Comp.129     Comp.130     Comp.131     Comp.132\n",
       "Standard deviation     4.540611e+01 45.214054593 4.495996e+01 4.468093e+01\n",
       "Proportion of Variance 5.999534e-04  0.000594889 5.882216e-04 5.809429e-04\n",
       "Cumulative Proportion  9.398430e-01  0.940437924 9.410261e-01 9.416071e-01\n",
       "                           Comp.133     Comp.134     Comp.135     Comp.136\n",
       "Standard deviation     4.441981e+01 4.381597e+01 4.366267e+01 4.334052e+01\n",
       "Proportion of Variance 5.741726e-04 5.586682e-04 5.547657e-04 5.466096e-04\n",
       "Cumulative Proportion  9.421813e-01 9.427399e-01 9.432947e-01 9.438413e-01\n",
       "                           Comp.137     Comp.138     Comp.139     Comp.140\n",
       "Standard deviation     4.305366e+01 4.269376e+01 4.249656e+01 4.220389e+01\n",
       "Proportion of Variance 5.393978e-04 5.304174e-04 5.255289e-04 5.183152e-04\n",
       "Cumulative Proportion  9.443807e-01 9.449111e-01 9.454366e-01 9.459550e-01\n",
       "                           Comp.141     Comp.142     Comp.143     Comp.144\n",
       "Standard deviation     4.191269e+01 4.159628e+01 4.138957e+01 4.105460e+01\n",
       "Proportion of Variance 5.111874e-04 5.034983e-04 4.985065e-04 4.904703e-04\n",
       "Cumulative Proportion  9.464662e-01 9.469696e-01 9.474682e-01 9.479586e-01\n",
       "                           Comp.145     Comp.146     Comp.147     Comp.148\n",
       "Standard deviation     4.089849e+01 4.044786e+01 4.036221e+01 3.997829e+01\n",
       "Proportion of Variance 4.867473e-04 4.760802e-04 4.740661e-04 4.650904e-04\n",
       "Cumulative Proportion  9.484454e-01 9.489215e-01 9.493955e-01 9.498606e-01\n",
       "                           Comp.149     Comp.150     Comp.151     Comp.152\n",
       "Standard deviation     3.986769e+01 3.959805e+01 3.918974e+01 3.892740e+01\n",
       "Proportion of Variance 4.625208e-04 4.562854e-04 4.469241e-04 4.409606e-04\n",
       "Cumulative Proportion  9.503231e-01 9.507794e-01 9.512263e-01 9.516673e-01\n",
       "                           Comp.153     Comp.154     Comp.155     Comp.156\n",
       "Standard deviation     3.886126e+01 3.872200e+01 3.862719e+01 3.844836e+01\n",
       "Proportion of Variance 4.394634e-04 4.363195e-04 4.341855e-04 4.301744e-04\n",
       "Cumulative Proportion  9.521068e-01 9.525431e-01 9.529773e-01 9.534074e-01\n",
       "                           Comp.157     Comp.158    Comp.159     Comp.160\n",
       "Standard deviation     3.824913e+01 3.782821e+01 37.41169067 3.713919e+01\n",
       "Proportion of Variance 4.257279e-04 4.164094e-04  0.00040729 4.013783e-04\n",
       "Cumulative Proportion  9.538332e-01 9.542496e-01  0.95465687 9.550582e-01\n",
       "                           Comp.161     Comp.162     Comp.163     Comp.164\n",
       "Standard deviation     3.706336e+01 3.666519e+01 3.653221e+01 3.620685e+01\n",
       "Proportion of Variance 3.997409e-04 3.911982e-04 3.883658e-04 3.814789e-04\n",
       "Cumulative Proportion  9.554580e-01 9.558492e-01 9.562376e-01 9.566190e-01\n",
       "                           Comp.165     Comp.166     Comp.167     Comp.168\n",
       "Standard deviation     3.605573e+01 3.578202e+01 35.552502227 3.545865e+01\n",
       "Proportion of Variance 3.783011e-04 3.725794e-04  0.000367815 3.658756e-04\n",
       "Cumulative Proportion  9.569973e-01 9.573699e-01  0.957737729 9.581036e-01\n",
       "                           Comp.169     Comp.170     Comp.171     Comp.172\n",
       "Standard deviation     3.533401e+01 3.512987e+01 3.507812e+01 3.488911e+01\n",
       "Proportion of Variance 3.633079e-04 3.591222e-04 3.580647e-04 3.542166e-04\n",
       "Cumulative Proportion  9.584669e-01 9.588260e-01 9.591841e-01 9.595383e-01\n",
       "                          Comp.173     Comp.174     Comp.175     Comp.176\n",
       "Standard deviation     34.78076563 3.471155e+01 34.528047779 3.441432e+01\n",
       "Proportion of Variance  0.00035202 3.506202e-04  0.000346923 3.446413e-04\n",
       "Cumulative Proportion   0.95989034 9.602410e-01  0.960587879 9.609325e-01\n",
       "                           Comp.177     Comp.178     Comp.179     Comp.180\n",
       "Standard deviation     3.411573e+01 3.393585e+01 3.370081e+01 3.363568e+01\n",
       "Proportion of Variance 3.386868e-04 3.351248e-04 3.304987e-04 3.292225e-04\n",
       "Cumulative Proportion  9.612712e-01 9.616063e-01 9.619368e-01 9.622661e-01\n",
       "                           Comp.181     Comp.182     Comp.183     Comp.184\n",
       "Standard deviation     33.477587853 3.322866e+01 33.181108341 3.304856e+01\n",
       "Proportion of Variance  0.000326135 3.213029e-04  0.000320384 3.178294e-04\n",
       "Cumulative Proportion   0.962592188 9.629135e-01  0.963233875 9.635517e-01\n",
       "                           Comp.185     Comp.186     Comp.187     Comp.188\n",
       "Standard deviation     3.291895e+01 3.278800e+01 3.270445e+01 3.258041e+01\n",
       "Proportion of Variance 3.153414e-04 3.128375e-04 3.112453e-04 3.088889e-04\n",
       "Cumulative Proportion  9.638670e-01 9.641799e-01 9.644911e-01 9.648000e-01\n",
       "                           Comp.189     Comp.190     Comp.191     Comp.192\n",
       "Standard deviation     3.244154e+01 32.243207539 3.200193e+01 3.194822e+01\n",
       "Proportion of Variance 3.062612e-04  0.000302528 2.980173e-04 2.970178e-04\n",
       "Cumulative Proportion  9.651063e-01  0.965408806 9.657068e-01 9.660038e-01\n",
       "                           Comp.193     Comp.194     Comp.195     Comp.196\n",
       "Standard deviation     3.172343e+01 3.152285e+01 3.145377e+01 3.116885e+01\n",
       "Proportion of Variance 2.928528e-04 2.891611e-04 2.878951e-04 2.827032e-04\n",
       "Cumulative Proportion  9.662967e-01 9.665859e-01 9.668738e-01 9.671565e-01\n",
       "                           Comp.197     Comp.198     Comp.199     Comp.200\n",
       "Standard deviation     3.112299e+01 3.095434e+01 3.081594e+01 3.066228e+01\n",
       "Proportion of Variance 2.818718e-04 2.788253e-04 2.763376e-04 2.735886e-04\n",
       "Cumulative Proportion  9.674383e-01 9.677172e-01 9.679935e-01 9.682671e-01\n",
       "                           Comp.201     Comp.202     Comp.203     Comp.204\n",
       "Standard deviation     3.058011e+01 3.043398e+01 3.027321e+01 2.999278e+01\n",
       "Proportion of Variance 2.721242e-04 2.695296e-04 2.666896e-04 2.617716e-04\n",
       "Cumulative Proportion  9.685392e-01 9.688087e-01 9.690754e-01 9.693372e-01\n",
       "                           Comp.205     Comp.206     Comp.207     Comp.208\n",
       "Standard deviation     2.994472e+01 2.984865e+01 2.976546e+01 2.964989e+01\n",
       "Proportion of Variance 2.609333e-04 2.592617e-04 2.578187e-04 2.558204e-04\n",
       "Cumulative Proportion  9.695981e-01 9.698574e-01 9.701152e-01 9.703710e-01\n",
       "                           Comp.209     Comp.210     Comp.211     Comp.212\n",
       "Standard deviation     2.959382e+01 2.950820e+01 29.489080965 2.933934e+01\n",
       "Proportion of Variance 2.548537e-04 2.533813e-04  0.000253053 2.504896e-04\n",
       "Cumulative Proportion  9.706259e-01 9.708793e-01  0.971132314 9.713828e-01\n",
       "                           Comp.213     Comp.214     Comp.215     Comp.216\n",
       "Standard deviation     2.912278e+01 2.901326e+01 2.889433e+01 2.885874e+01\n",
       "Proportion of Variance 2.468055e-04 2.449526e-04 2.429486e-04 2.423504e-04\n",
       "Cumulative Proportion  9.716296e-01 9.718746e-01 9.721175e-01 9.723599e-01\n",
       "                           Comp.217     Comp.218     Comp.219     Comp.220\n",
       "Standard deviation     2.871497e+01 2.858749e+01 2.852888e+01 2.832737e+01\n",
       "Proportion of Variance 2.399417e-04 2.378159e-04 2.368419e-04 2.335079e-04\n",
       "Cumulative Proportion  9.725998e-01 9.728376e-01 9.730745e-01 9.733080e-01\n",
       "                           Comp.221     Comp.222     Comp.223     Comp.224\n",
       "Standard deviation     28.215975662 2.803365e+01 2.793612e+01 2.785608e+01\n",
       "Proportion of Variance  0.000231675 2.286905e-04 2.271021e-04 2.258026e-04\n",
       "Cumulative Proportion   0.973539643 9.737683e-01 9.739954e-01 9.742212e-01\n",
       "                           Comp.225     Comp.226     Comp.227     Comp.228\n",
       "Standard deviation     2.781211e+01 27.702269955 2.760607e+01 2.743159e+01\n",
       "Proportion of Variance 2.250904e-04  0.000223316 2.217677e-04 2.189732e-04\n",
       "Cumulative Proportion  9.744463e-01  0.974669645 9.748914e-01 9.751104e-01\n",
       "                           Comp.229     Comp.230     Comp.231     Comp.232\n",
       "Standard deviation     2.738321e+01 2.715453e+01 2.711422e+01 2.702266e+01\n",
       "Proportion of Variance 2.182015e-04 2.145722e-04 2.139356e-04 2.124932e-04\n",
       "Cumulative Proportion  9.753286e-01 9.755432e-01 9.757571e-01 9.759696e-01\n",
       "                           Comp.233     Comp.234     Comp.235     Comp.236\n",
       "Standard deviation     2.691351e+01 2.684290e+01 2.673165e+01 26.669666026\n",
       "Proportion of Variance 2.107802e-04 2.096757e-04 2.079412e-04  0.000206978\n",
       "Cumulative Proportion  9.761804e-01 9.763900e-01 9.765980e-01  0.976804963\n",
       "                           Comp.237     Comp.238     Comp.239     Comp.240\n",
       "Standard deviation     2.659423e+01 2.648568e+01 2.645061e+01 2.615694e+01\n",
       "Proportion of Variance 2.058088e-04 2.041321e-04 2.035918e-04 1.990961e-04\n",
       "Cumulative Proportion  9.770108e-01 9.772149e-01 9.774185e-01 9.776176e-01\n",
       "                           Comp.241     Comp.242     Comp.243     Comp.244\n",
       "Standard deviation     2.607923e+01 2.602985e+01 2.594638e+01 2.580006e+01\n",
       "Proportion of Variance 1.979149e-04 1.971661e-04 1.959037e-04 1.937004e-04\n",
       "Cumulative Proportion  9.778155e-01 9.780127e-01 9.782086e-01 9.784023e-01\n",
       "                           Comp.245     Comp.246     Comp.247     Comp.248\n",
       "Standard deviation     2.567795e+01 2.561407e+01 2.549908e+01 2.548246e+01\n",
       "Proportion of Variance 1.918711e-04 1.909178e-04 1.892074e-04 1.889608e-04\n",
       "Cumulative Proportion  9.785941e-01 9.787851e-01 9.789743e-01 9.791632e-01\n",
       "                           Comp.249     Comp.250     Comp.251     Comp.252\n",
       "Standard deviation     2.533162e+01 25.251908203 2.516658e+01 2.514807e+01\n",
       "Proportion of Variance 1.867304e-04  0.000185557 1.843051e-04 1.840341e-04\n",
       "Cumulative Proportion  9.793500e-01  0.979535522 9.797198e-01 9.799039e-01\n",
       "                           Comp.253     Comp.254     Comp.255     Comp.256\n",
       "Standard deviation     2.511507e+01 2.503086e+01 2.486606e+01 2.468088e+01\n",
       "Proportion of Variance 1.835514e-04 1.823227e-04 1.799298e-04 1.772598e-04\n",
       "Cumulative Proportion  9.800874e-01 9.802697e-01 9.804497e-01 9.806269e-01\n",
       "                           Comp.257     Comp.258     Comp.259     Comp.260\n",
       "Standard deviation     2.460519e+01 2.458250e+01 2.451356e+01 2.450361e+01\n",
       "Proportion of Variance 1.761743e-04 1.758495e-04 1.748645e-04 1.747226e-04\n",
       "Cumulative Proportion  9.808031e-01 9.809789e-01 9.811538e-01 9.813285e-01\n",
       "                           Comp.261     Comp.262     Comp.263     Comp.264\n",
       "Standard deviation     24.372577160 2.431376e+01 2.415677e+01 2.408591e+01\n",
       "Proportion of Variance  0.000172859 1.720257e-04 1.698113e-04 1.688165e-04\n",
       "Cumulative Proportion   0.981501395 9.816734e-01 9.818432e-01 9.820120e-01\n",
       "                           Comp.265     Comp.266     Comp.267     Comp.268\n",
       "Standard deviation     2.405021e+01 2.396465e+01 2.385071e+01 23.746115581\n",
       "Proportion of Variance 1.683165e-04 1.671211e-04 1.655357e-04  0.000164087\n",
       "Cumulative Proportion  9.821804e-01 9.823475e-01 9.825130e-01  0.982677109\n",
       "                           Comp.269     Comp.270     Comp.271     Comp.272\n",
       "Standard deviation     2.370977e+01 2.362706e+01 2.351919e+01 2.338929e+01\n",
       "Proportion of Variance 1.635852e-04 1.624457e-04 1.609659e-04 1.591927e-04\n",
       "Cumulative Proportion  9.828407e-01 9.830031e-01 9.831641e-01 9.833233e-01\n",
       "                           Comp.273     Comp.274     Comp.275     Comp.276\n",
       "Standard deviation     2.330708e+01 2.320632e+01 2.308868e+01 2.305228e+01\n",
       "Proportion of Variance 1.580755e-04 1.567117e-04 1.551269e-04 1.546382e-04\n",
       "Cumulative Proportion  9.834814e-01 9.836381e-01 9.837932e-01 9.839479e-01\n",
       "                           Comp.277     Comp.278     Comp.279     Comp.280\n",
       "Standard deviation     22.970127414 2.292629e+01 2.286718e+01 22.782883984\n",
       "Proportion of Variance  0.000153538 1.529525e-04 1.521648e-04  0.000151045\n",
       "Cumulative Proportion   0.984101388 9.842543e-01 9.844065e-01  0.984557551\n",
       "                           Comp.281     Comp.282     Comp.283     Comp.284\n",
       "Standard deviation     2.264769e+01 2.255680e+01 2.251831e+01 2.243598e+01\n",
       "Proportion of Variance 1.492578e-04 1.480622e-04 1.475573e-04 1.464803e-04\n",
       "Cumulative Proportion  9.847068e-01 9.848549e-01 9.850024e-01 9.851489e-01\n",
       "                           Comp.285     Comp.286     Comp.287     Comp.288\n",
       "Standard deviation     2.233814e+01 22.199370465 2.218841e+01 2.210065e+01\n",
       "Proportion of Variance 1.452055e-04  0.000143407 1.432654e-04 1.421343e-04\n",
       "Cumulative Proportion  9.852941e-01  0.985437521 9.855808e-01 9.857229e-01\n",
       "                           Comp.289     Comp.290     Comp.291     Comp.292\n",
       "Standard deviation     2.208776e+01 2.192656e+01 2.186339e+01 2.175285e+01\n",
       "Proportion of Variance 1.419686e-04 1.399039e-04 1.390991e-04 1.376961e-04\n",
       "Cumulative Proportion  9.858649e-01 9.860048e-01 9.861439e-01 9.862816e-01\n",
       "                           Comp.293     Comp.294     Comp.295     Comp.296\n",
       "Standard deviation     2.171779e+01 2.153698e+01 2.150730e+01 2.141543e+01\n",
       "Proportion of Variance 1.372525e-04 1.349766e-04 1.346048e-04 1.334574e-04\n",
       "Cumulative Proportion  9.864188e-01 9.865538e-01 9.866884e-01 9.868219e-01\n",
       "                           Comp.297     Comp.298     Comp.299     Comp.300\n",
       "Standard deviation     2.138700e+01 2.127347e+01 2.121382e+01 21.139872664\n",
       "Proportion of Variance 1.331032e-04 1.316939e-04 1.309564e-04  0.000130045\n",
       "Cumulative Proportion  9.869550e-01 9.870867e-01 9.872176e-01  0.987347678\n",
       "                           Comp.301     Comp.302     Comp.303     Comp.304\n",
       "Standard deviation     2.107133e+01 2.105703e+01 2.093851e+01 20.926819121\n",
       "Proportion of Variance 1.292031e-04 1.290278e-04 1.275794e-04  0.000127437\n",
       "Cumulative Proportion  9.874769e-01 9.876059e-01 9.877335e-01  0.987860925\n",
       "                           Comp.305     Comp.306     Comp.307     Comp.308\n",
       "Standard deviation     2.081176e+01 2.062506e+01 20.602613813 2.046972e+01\n",
       "Proportion of Variance 1.260395e-04 1.237883e-04  0.000123519 1.219306e-04\n",
       "Cumulative Proportion  9.879870e-01 9.881108e-01  0.988234272 9.883562e-01\n",
       "                           Comp.309     Comp.310     Comp.311     Comp.312\n",
       "Standard deviation     2.042416e+01 2.036134e+01 2.023562e+01 2.018541e+01\n",
       "Proportion of Variance 1.213885e-04 1.206429e-04 1.191577e-04 1.185671e-04\n",
       "Cumulative Proportion  9.884776e-01 9.885982e-01 9.887174e-01 9.888360e-01\n",
       "                           Comp.313     Comp.314     Comp.315     Comp.316\n",
       "Standard deviation     2.007747e+01 2.002484e+01 1.997561e+01 1.991955e+01\n",
       "Proportion of Variance 1.173024e-04 1.166883e-04 1.161152e-04 1.154644e-04\n",
       "Cumulative Proportion  9.889533e-01 9.890699e-01 9.891861e-01 9.893015e-01\n",
       "                           Comp.317     Comp.318     Comp.319     Comp.320\n",
       "Standard deviation     1.978983e+01 1.976843e+01 1.964829e+01 19.608633280\n",
       "Proportion of Variance 1.139654e-04 1.137191e-04 1.123411e-04  0.000111888\n",
       "Cumulative Proportion  9.894155e-01 9.895292e-01 9.896416e-01  0.989753443\n",
       "                           Comp.321     Comp.322     Comp.323     Comp.324\n",
       "Standard deviation     1.959186e+01 1.950850e+01 1.937163e+01 1.936262e+01\n",
       "Proportion of Variance 1.116967e-04 1.107482e-04 1.091996e-04 1.090981e-04\n",
       "Cumulative Proportion  9.898651e-01 9.899759e-01 9.900851e-01 9.901942e-01\n",
       "                           Comp.325     Comp.326     Comp.327     Comp.328\n",
       "Standard deviation     1.928627e+01 1.923775e+01 1.909632e+01 1.905882e+01\n",
       "Proportion of Variance 1.082394e-04 1.076955e-04 1.061178e-04 1.057015e-04\n",
       "Cumulative Proportion  9.903024e-01 9.904101e-01 9.905162e-01 9.906219e-01\n",
       "                           Comp.329     Comp.330     Comp.331     Comp.332\n",
       "Standard deviation     1.900671e+01 1.892028e+01 1.884658e+01 1.873849e+01\n",
       "Proportion of Variance 1.051242e-04 1.041704e-04 1.033604e-04 1.021782e-04\n",
       "Cumulative Proportion  9.907271e-01 9.908312e-01 9.909346e-01 9.910368e-01\n",
       "                           Comp.333     Comp.334     Comp.335     Comp.336\n",
       "Standard deviation     1.870363e+01 1.866652e+01 1.862707e+01 1.852747e+01\n",
       "Proportion of Variance 1.017983e-04 1.013948e-04 1.009667e-04 9.988980e-05\n",
       "Cumulative Proportion  9.911386e-01 9.912400e-01 9.913409e-01 9.914408e-01\n",
       "                           Comp.337     Comp.338     Comp.339     Comp.340\n",
       "Standard deviation     1.850016e+01 1.836825e+01 1.828113e+01 1.824673e+01\n",
       "Proportion of Variance 9.959552e-05 9.818033e-05 9.725126e-05 9.688561e-05\n",
       "Cumulative Proportion  9.915404e-01 9.916386e-01 9.917358e-01 9.918327e-01\n",
       "                           Comp.341     Comp.342     Comp.343     Comp.344\n",
       "Standard deviation     1.817989e+01 1.807842e+01 1.802073e+01 1.796541e+01\n",
       "Proportion of Variance 9.617712e-05 9.510644e-05 9.450045e-05 9.392110e-05\n",
       "Cumulative Proportion  9.919289e-01 9.920240e-01 9.921185e-01 9.922124e-01\n",
       "                           Comp.345     Comp.346     Comp.347     Comp.348\n",
       "Standard deviation     1.794813e+01 1.775970e+01 1.774084e+01 1.769007e+01\n",
       "Proportion of Variance 9.374052e-05 9.178262e-05 9.158777e-05 9.106427e-05\n",
       "Cumulative Proportion  9.923062e-01 9.923980e-01 9.924896e-01 9.925806e-01\n",
       "                           Comp.349     Comp.350     Comp.351     Comp.352\n",
       "Standard deviation     1.766506e+01 1.743189e+01 1.741341e+01 1.739337e+01\n",
       "Proportion of Variance 9.080703e-05 8.842561e-05 8.823826e-05 8.803526e-05\n",
       "Cumulative Proportion  9.926714e-01 9.927598e-01 9.928481e-01 9.929361e-01\n",
       "                           Comp.353     Comp.354     Comp.355     Comp.356\n",
       "Standard deviation     1.730769e+01 1.722344e+01 1.720607e+01 1.716432e+01\n",
       "Proportion of Variance 8.717005e-05 8.632348e-05 8.614941e-05 8.573186e-05\n",
       "Cumulative Proportion  9.930233e-01 9.931096e-01 9.931958e-01 9.932815e-01\n",
       "                           Comp.357     Comp.358     Comp.359     Comp.360\n",
       "Standard deviation     1.705244e+01 1.699348e+01 1.685512e+01 1.681932e+01\n",
       "Proportion of Variance 8.461783e-05 8.403378e-05 8.267093e-05 8.232014e-05\n",
       "Cumulative Proportion  9.933661e-01 9.934501e-01 9.935328e-01 9.936151e-01\n",
       "                           Comp.361     Comp.362     Comp.363     Comp.364\n",
       "Standard deviation     1.675092e+01 1.671757e+01 1.657451e+01 1.643717e+01\n",
       "Proportion of Variance 8.165195e-05 8.132715e-05 7.994120e-05 7.862182e-05\n",
       "Cumulative Proportion  9.936968e-01 9.937781e-01 9.938581e-01 9.939367e-01\n",
       "                           Comp.365     Comp.366     Comp.367     Comp.368\n",
       "Standard deviation     1.640516e+01 1.633353e+01 1.627632e+01 1.625599e+01\n",
       "Proportion of Variance 7.831592e-05 7.763345e-05 7.709061e-05 7.689816e-05\n",
       "Cumulative Proportion  9.940150e-01 9.940926e-01 9.941697e-01 9.942466e-01\n",
       "                           Comp.369     Comp.370     Comp.371     Comp.372\n",
       "Standard deviation     1.618082e+01 1.610993e+01 1.604735e+01 1.593641e+01\n",
       "Proportion of Variance 7.618866e-05 7.552246e-05 7.493691e-05 7.390433e-05\n",
       "Cumulative Proportion  9.943228e-01 9.943983e-01 9.944733e-01 9.945472e-01\n",
       "                           Comp.373     Comp.374     Comp.375     Comp.376\n",
       "Standard deviation     1.589455e+01 1.581626e+01 1.576771e+01 1.572993e+01\n",
       "Proportion of Variance 7.351663e-05 7.279418e-05 7.234794e-05 7.200168e-05\n",
       "Cumulative Proportion  9.946207e-01 9.946935e-01 9.947658e-01 9.948378e-01\n",
       "                           Comp.377    Comp.378     Comp.379     Comp.380\n",
       "Standard deviation     1.563344e+01 1.56202e+01 1.548343e+01 1.532800e+01\n",
       "Proportion of Variance 7.112109e-05 7.10006e-05 6.976274e-05 6.836916e-05\n",
       "Cumulative Proportion  9.949090e-01 9.94980e-01 9.950497e-01 9.951181e-01\n",
       "                           Comp.381     Comp.382     Comp.383     Comp.384\n",
       "Standard deviation     1.527556e+01 1.523594e+01 1.516115e+01 1.506681e+01\n",
       "Proportion of Variance 6.790214e-05 6.755037e-05 6.688876e-05 6.605892e-05\n",
       "Cumulative Proportion  9.951860e-01 9.952535e-01 9.953204e-01 9.953865e-01\n",
       "                           Comp.385     Comp.386     Comp.387     Comp.388\n",
       "Standard deviation     1.499324e+01 1.490363e+01 1.479690e+01 1.471840e+01\n",
       "Proportion of Variance 6.541536e-05 6.463576e-05 6.371338e-05 6.303912e-05\n",
       "Cumulative Proportion  9.954519e-01 9.955165e-01 9.955803e-01 9.956433e-01\n",
       "                           Comp.389     Comp.390     Comp.391     Comp.392\n",
       "Standard deviation     1.459658e+01 1.453101e+01 1.451385e+01 1.440179e+01\n",
       "Proportion of Variance 6.199993e-05 6.144420e-05 6.129911e-05 6.035623e-05\n",
       "Cumulative Proportion  9.957053e-01 9.957667e-01 9.958280e-01 9.958884e-01\n",
       "                           Comp.393     Comp.394     Comp.395     Comp.396\n",
       "Standard deviation     1.435913e+01 1.425408e+01 1.412602e+01 1.406048e+01\n",
       "Proportion of Variance 5.999916e-05 5.912451e-05 5.806692e-05 5.752935e-05\n",
       "Cumulative Proportion  9.959484e-01 9.960075e-01 9.960656e-01 9.961231e-01\n",
       "                           Comp.397     Comp.398     Comp.399     Comp.400\n",
       "Standard deviation     1.399879e+01 1.394953e+01 1.383935e+01 1.374099e+01\n",
       "Proportion of Variance 5.702562e-05 5.662499e-05 5.573402e-05 5.494463e-05\n",
       "Cumulative Proportion  9.961801e-01 9.962368e-01 9.962925e-01 9.963474e-01\n",
       "                           Comp.401     Comp.402     Comp.403     Comp.404\n",
       "Standard deviation     1.364895e+01 1.357110e+01 1.352756e+01 1.342049e+01\n",
       "Proportion of Variance 5.421105e-05 5.359438e-05 5.325103e-05 5.241142e-05\n",
       "Cumulative Proportion  9.964016e-01 9.964552e-01 9.965085e-01 9.965609e-01\n",
       "                           Comp.405     Comp.406     Comp.407     Comp.408\n",
       "Standard deviation     1.336359e+01 1.329132e+01 1.316568e+01 1.312521e+01\n",
       "Proportion of Variance 5.196794e-05 5.140737e-05 5.044005e-05 5.013042e-05\n",
       "Cumulative Proportion  9.966129e-01 9.966643e-01 9.967147e-01 9.967649e-01\n",
       "                           Comp.409     Comp.410     Comp.411     Comp.412\n",
       "Standard deviation     1.295484e+01 1.288276e+01 1.280268e+01 1.277216e+01\n",
       "Proportion of Variance 4.883748e-05 4.829555e-05 4.769697e-05 4.746983e-05\n",
       "Cumulative Proportion  9.968137e-01 9.968620e-01 9.969097e-01 9.969572e-01\n",
       "                           Comp.413     Comp.414     Comp.415     Comp.416\n",
       "Standard deviation     1.273082e+01 1.262530e+01 1.255260e+01 1.248148e+01\n",
       "Proportion of Variance 4.716306e-05 4.638442e-05 4.585181e-05 4.533369e-05\n",
       "Cumulative Proportion  9.970043e-01 9.970507e-01 9.970966e-01 9.971419e-01\n",
       "                           Comp.417     Comp.418     Comp.419     Comp.420\n",
       "Standard deviation     1.241232e+01 1.236299e+01 1.222678e+01 1.222104e+01\n",
       "Proportion of Variance 4.483273e-05 4.447706e-05 4.350238e-05 4.346156e-05\n",
       "Cumulative Proportion  9.971867e-01 9.972312e-01 9.972747e-01 9.973182e-01\n",
       "                           Comp.421     Comp.422     Comp.423     Comp.424\n",
       "Standard deviation     1.211682e+01 1.201229e+01 1.191000e+01 1.187354e+01\n",
       "Proportion of Variance 4.272342e-05 4.198953e-05 4.127745e-05 4.102508e-05\n",
       "Cumulative Proportion  9.973609e-01 9.974029e-01 9.974441e-01 9.974852e-01\n",
       "                           Comp.425     Comp.426     Comp.427     Comp.428\n",
       "Standard deviation     1.172368e+01 1.160767e+01 1.157171e+01 1.149708e+01\n",
       "Proportion of Variance 3.999603e-05 3.920843e-05 3.896582e-05 3.846489e-05\n",
       "Cumulative Proportion  9.975252e-01 9.975644e-01 9.976033e-01 9.976418e-01\n",
       "                           Comp.429     Comp.430     Comp.431     Comp.432\n",
       "Standard deviation     1.147956e+01 1.135550e+01 1.125305e+01 1.120760e+01\n",
       "Proportion of Variance 3.834769e-05 3.752335e-05 3.684931e-05 3.655225e-05\n",
       "Cumulative Proportion  9.976802e-01 9.977177e-01 9.977545e-01 9.977911e-01\n",
       "                           Comp.433     Comp.434     Comp.435     Comp.436\n",
       "Standard deviation     1.114983e+01 1.103182e+01 1.100285e+01 1.092186e+01\n",
       "Proportion of Variance 3.617639e-05 3.541468e-05 3.522890e-05 3.471222e-05\n",
       "Cumulative Proportion  9.978273e-01 9.978627e-01 9.978979e-01 9.979326e-01\n",
       "                           Comp.437     Comp.438     Comp.439     Comp.440\n",
       "Standard deviation     1.088097e+01 1.082233e+01 1.068400e+01 1.064964e+01\n",
       "Proportion of Variance 3.445278e-05 3.408244e-05 3.321675e-05 3.300341e-05\n",
       "Cumulative Proportion  9.979671e-01 9.980011e-01 9.980344e-01 9.980674e-01\n",
       "                           Comp.441     Comp.442     Comp.443     Comp.444\n",
       "Standard deviation     1.053823e+01 1.047198e+01 1.040230e+01 1.027657e+01\n",
       "Proportion of Variance 3.231649e-05 3.191144e-05 3.148819e-05 3.073159e-05\n",
       "Cumulative Proportion  9.980997e-01 9.981316e-01 9.981631e-01 9.981938e-01\n",
       "                           Comp.445     Comp.446     Comp.447     Comp.448\n",
       "Standard deviation     1.023633e+01 1.022901e+01 1.008069e+01 9.991882e+00\n",
       "Proportion of Variance 3.049140e-05 3.044784e-05 2.957122e-05 2.905251e-05\n",
       "Cumulative Proportion  9.982243e-01 9.982548e-01 9.982843e-01 9.983134e-01\n",
       "                           Comp.449     Comp.450     Comp.451     Comp.452\n",
       "Standard deviation     9.968015e+00 9.945589e+00 9.834356e+00 9.7673548089\n",
       "Proportion of Variance 2.891388e-05 2.878393e-05 2.814368e-05 0.0000277615\n",
       "Cumulative Proportion  9.983423e-01 9.983711e-01 9.983992e-01 0.9984269829\n",
       "                           Comp.453     Comp.454     Comp.455     Comp.456\n",
       "Standard deviation     9.6798854167 9.624519e+00 9.549024e+00 9.537845e+00\n",
       "Proportion of Variance 0.0000272665 2.695548e-05 2.653426e-05 2.647217e-05\n",
       "Cumulative Proportion  0.9984542494 9.984812e-01 9.985077e-01 9.985342e-01\n",
       "                           Comp.457     Comp.458     Comp.459     Comp.460\n",
       "Standard deviation     9.522839e+00 9.467035e+00 9.383130e+00 9.350708e+00\n",
       "Proportion of Variance 2.638894e-05 2.608056e-05 2.562032e-05 2.544357e-05\n",
       "Cumulative Proportion  9.985606e-01 9.985867e-01 9.986123e-01 9.986377e-01\n",
       "                           Comp.461     Comp.462     Comp.463     Comp.464\n",
       "Standard deviation     9.220172e+00 9.149633e+00 9.090987e+00 9.033390e+00\n",
       "Proportion of Variance 2.473814e-05 2.436107e-05 2.404978e-05 2.374601e-05\n",
       "Cumulative Proportion  9.986625e-01 9.986868e-01 9.987109e-01 9.987346e-01\n",
       "                           Comp.465     Comp.466     Comp.467     Comp.468\n",
       "Standard deviation     8.924460e+00 8.907126e+00 8.855464e+00 8.805353e+00\n",
       "Proportion of Variance 2.317677e-05 2.308683e-05 2.281979e-05 2.256226e-05\n",
       "Cumulative Proportion  9.987578e-01 9.987809e-01 9.988037e-01 9.988263e-01\n",
       "                           Comp.469     Comp.470     Comp.471     Comp.472\n",
       "Standard deviation     8.731756e+00 8.642739e+00 8.584177e+00 8.550197e+00\n",
       "Proportion of Variance 2.218667e-05 2.173661e-05 2.144304e-05 2.127361e-05\n",
       "Cumulative Proportion  9.988485e-01 9.988702e-01 9.988917e-01 9.989129e-01\n",
       "                           Comp.473     Comp.474     Comp.475     Comp.476\n",
       "Standard deviation     8.532366e+00 8.411347e+00 8.325651e+00 8.267140e+00\n",
       "Proportion of Variance 2.118498e-05 2.058828e-05 2.017091e-05 1.988839e-05\n",
       "Cumulative Proportion  9.989341e-01 9.989547e-01 9.989749e-01 9.989948e-01\n",
       "                           Comp.477     Comp.478     Comp.479     Comp.480\n",
       "Standard deviation     8.251181e+00 8.199461e+00 8.124338e+00 8.100584e+00\n",
       "Proportion of Variance 1.981168e-05 1.956409e-05 1.920724e-05 1.909509e-05\n",
       "Cumulative Proportion  9.990146e-01 9.990341e-01 9.990533e-01 9.990724e-01\n",
       "                           Comp.481     Comp.482     Comp.483     Comp.484\n",
       "Standard deviation     8.075687e+00 7.969454e+00 7.894433e+00 7.783374e+00\n",
       "Proportion of Variance 1.897789e-05 1.848188e-05 1.813556e-05 1.762888e-05\n",
       "Cumulative Proportion  9.990914e-01 9.991099e-01 9.991280e-01 9.991457e-01\n",
       "                           Comp.485     Comp.486     Comp.487     Comp.488\n",
       "Standard deviation     7.7799102745 7.699197e+00 7.6603703894 7.563575e+00\n",
       "Proportion of Variance 0.0000176132 1.724963e-05 0.0000170761 1.664728e-05\n",
       "Cumulative Proportion  0.9991632734 9.991805e-01 0.9991975991 9.992142e-01\n",
       "                           Comp.489     Comp.490     Comp.491     Comp.492\n",
       "Standard deviation     7.532702e+00 7.529705e+00 7.495505e+00 7.427521e+00\n",
       "Proportion of Variance 1.651165e-05 1.649852e-05 1.634899e-05 1.605376e-05\n",
       "Cumulative Proportion  9.992308e-01 9.992473e-01 9.992636e-01 9.992797e-01\n",
       "                           Comp.493     Comp.494     Comp.495     Comp.496\n",
       "Standard deviation     7.307271e+00 7.252583e+00 7.138834e+00 7.050599e+00\n",
       "Proportion of Variance 1.553815e-05 1.530645e-05 1.483008e-05 1.446575e-05\n",
       "Cumulative Proportion  9.992952e-01 9.993105e-01 9.993253e-01 9.993398e-01\n",
       "                           Comp.497     Comp.498     Comp.499     Comp.500\n",
       "Standard deviation     7.031353e+00 6.902388e+00 6.867326e+00 6.796241e+00\n",
       "Proportion of Variance 1.438689e-05 1.386397e-05 1.372348e-05 1.344084e-05\n",
       "Cumulative Proportion  9.993542e-01 9.993681e-01 9.993818e-01 9.993952e-01\n",
       "                           Comp.501     Comp.502     Comp.503     Comp.504\n",
       "Standard deviation     6.769618e+00 6.678399e+00 6.599343e+00 6.550121e+00\n",
       "Proportion of Variance 1.333575e-05 1.297878e-05 1.267332e-05 1.248498e-05\n",
       "Cumulative Proportion  9.994086e-01 9.994215e-01 9.994342e-01 9.994467e-01\n",
       "                           Comp.505     Comp.506     Comp.507     Comp.508\n",
       "Standard deviation     6.533301e+00 6.494102e+00 6.418947e+00 6.329150e+00\n",
       "Proportion of Variance 1.242094e-05 1.227234e-05 1.198993e-05 1.165681e-05\n",
       "Cumulative Proportion  9.994591e-01 9.994714e-01 9.994834e-01 9.994950e-01\n",
       "                           Comp.509     Comp.510     Comp.511     Comp.512\n",
       "Standard deviation     6.312780e+00 6.200102e+00 6.157688e+00 6.150260e+00\n",
       "Proportion of Variance 1.159659e-05 1.118631e-05 1.103378e-05 1.100718e-05\n",
       "Cumulative Proportion  9.995066e-01 9.995178e-01 9.995288e-01 9.995399e-01\n",
       "                           Comp.513     Comp.514     Comp.515     Comp.516\n",
       "Standard deviation     6.062884e+00 6.051146e+00 5.937148e+00 5.879139e+00\n",
       "Proportion of Variance 1.069665e-05 1.065527e-05 1.025758e-05 1.005811e-05\n",
       "Cumulative Proportion  9.995505e-01 9.995612e-01 9.995715e-01 9.995815e-01\n",
       "                           Comp.517     Comp.518     Comp.519     Comp.520\n",
       "Standard deviation     5.821129e+00 5.788312e+00 5.771667e+00 5.710858e+00\n",
       "Proportion of Variance 9.860603e-06 9.749736e-06 9.693744e-06 9.490558e-06\n",
       "Cumulative Proportion  9.995914e-01 9.996011e-01 9.996108e-01 9.996203e-01\n",
       "                           Comp.521     Comp.522     Comp.523     Comp.524\n",
       "Standard deviation     5.665615e+00 5.574171e+00 5.496370e+00 5.454196e+00\n",
       "Proportion of Variance 9.340780e-06 9.041691e-06 8.791055e-06 8.656662e-06\n",
       "Cumulative Proportion  9.996297e-01 9.996387e-01 9.996475e-01 9.996561e-01\n",
       "                           Comp.525     Comp.526     Comp.527     Comp.528\n",
       "Standard deviation     5.423468e+00 5.405831e+00 5.380323e+00 5.298980e+00\n",
       "Proportion of Variance 8.559398e-06 8.503819e-06 8.423756e-06 8.170969e-06\n",
       "Cumulative Proportion  9.996647e-01 9.996732e-01 9.996816e-01 9.996898e-01\n",
       "                           Comp.529     Comp.530     Comp.531     Comp.532\n",
       "Standard deviation     5.240990e+00 5.191182e+00 5.182810e+00 5.070935e+00\n",
       "Proportion of Variance 7.993107e-06 7.841904e-06 7.816631e-06 7.482817e-06\n",
       "Cumulative Proportion  9.996978e-01 9.997056e-01 9.997135e-01 9.997209e-01\n",
       "                           Comp.533     Comp.534     Comp.535     Comp.536\n",
       "Standard deviation     5.007435e+00 4.967043e+00 4.928633e+00 4.874598e+00\n",
       "Proportion of Variance 7.296586e-06 7.179346e-06 7.068740e-06 6.914594e-06\n",
       "Cumulative Proportion  9.997282e-01 9.997354e-01 9.997425e-01 9.997494e-01\n",
       "                           Comp.537     Comp.538     Comp.539     Comp.540\n",
       "Standard deviation     4.853145e+00 4.784404e+00 4.718654e+00 4.707593e+00\n",
       "Proportion of Variance 6.853866e-06 6.661081e-06 6.479257e-06 6.448919e-06\n",
       "Cumulative Proportion  9.997562e-01 9.997629e-01 9.997694e-01 9.997758e-01\n",
       "                           Comp.541     Comp.542     Comp.543     Comp.544\n",
       "Standard deviation     4.666187e+00 4.640772e+00 4.558149e+00 4.505794e+00\n",
       "Proportion of Variance 6.335972e-06 6.267142e-06 6.045971e-06 5.907880e-06\n",
       "Cumulative Proportion  9.997822e-01 9.997884e-01 9.997945e-01 9.998004e-01\n",
       "                           Comp.545     Comp.546     Comp.547     Comp.548\n",
       "Standard deviation     4.491444e+00 4.470420e+00 4.440921e+00 4.388624e+00\n",
       "Proportion of Variance 5.870309e-06 5.815481e-06 5.738985e-06 5.604614e-06\n",
       "Cumulative Proportion  9.998063e-01 9.998121e-01 9.998178e-01 9.998234e-01\n",
       "                           Comp.549     Comp.550     Comp.551     Comp.552\n",
       "Standard deviation     4.350899e+00 4.327993e+00 4.139977e+00 4.136428e+00\n",
       "Proportion of Variance 5.508674e-06 5.450824e-06 4.987522e-06 4.978975e-06\n",
       "Cumulative Proportion  9.998289e-01 9.998344e-01 9.998394e-01 9.998444e-01\n",
       "                           Comp.553     Comp.554     Comp.555     Comp.556\n",
       "Standard deviation     4.091776e+00 4.020954e+00 3.969982e+00 3.917418e+00\n",
       "Proportion of Variance 4.872061e-06 4.704866e-06 4.586339e-06 4.465692e-06\n",
       "Cumulative Proportion  9.998492e-01 9.998539e-01 9.998585e-01 9.998630e-01\n",
       "                           Comp.557     Comp.558     Comp.559     Comp.560\n",
       "Standard deviation     3.858323e+00 3.798527e+00 3.760201e+00 3.697613e+00\n",
       "Proportion of Variance 4.331977e-06 4.198744e-06 4.114444e-06 3.978616e-06\n",
       "Cumulative Proportion  9.998673e-01 9.998715e-01 9.998756e-01 9.998796e-01\n",
       "                           Comp.561     Comp.562     Comp.563     Comp.564\n",
       "Standard deviation     3.624443e+00 3.508687e+00 3.488879e+00 3.411105e+00\n",
       "Proportion of Variance 3.822712e-06 3.582435e-06 3.542101e-06 3.385940e-06\n",
       "Cumulative Proportion  9.998834e-01 9.998870e-01 9.998906e-01 9.998939e-01\n",
       "                           Comp.565     Comp.566     Comp.567     Comp.568\n",
       "Standard deviation     3.391044e+00 3.366306e+00 3.316250e+00 3.286932e+00\n",
       "Proportion of Variance 3.346231e-06 3.297587e-06 3.200248e-06 3.143913e-06\n",
       "Cumulative Proportion  9.998973e-01 9.999006e-01 9.999038e-01 9.999069e-01\n",
       "                           Comp.569     Comp.570     Comp.571     Comp.572\n",
       "Standard deviation     3.278613e+00 3.266598e+00 3.101557e+00 3.056577e+00\n",
       "Proportion of Variance 3.128019e-06 3.105134e-06 2.799294e-06 2.718691e-06\n",
       "Cumulative Proportion  9.999101e-01 9.999132e-01 9.999160e-01 9.999187e-01\n",
       "                           Comp.573     Comp.574     Comp.575     Comp.576\n",
       "Standard deviation     3.052403e+00 3.021293e+00 3.004178e+00 2.976038e+00\n",
       "Proportion of Variance 2.711270e-06 2.656285e-06 2.626275e-06 2.577305e-06\n",
       "Cumulative Proportion  9.999214e-01 9.999240e-01 9.999267e-01 9.999292e-01\n",
       "                           Comp.577     Comp.578     Comp.579     Comp.580\n",
       "Standard deviation     2.949430e+00 2.938284e+00 2.906082e+00 2.884785e+00\n",
       "Proportion of Variance 2.531426e-06 2.512329e-06 2.457563e-06 2.421676e-06\n",
       "Cumulative Proportion  9.999318e-01 9.999343e-01 9.999367e-01 9.999392e-01\n",
       "                           Comp.581     Comp.582     Comp.583     Comp.584\n",
       "Standard deviation     2.837505e+00 2.808416e+00 2.770037e+00 2.742006e+00\n",
       "Proportion of Variance 2.342946e-06 2.295154e-06 2.232854e-06 2.187891e-06\n",
       "Cumulative Proportion  9.999415e-01 9.999438e-01 9.999460e-01 9.999482e-01\n",
       "                           Comp.585     Comp.586     Comp.587     Comp.588\n",
       "Standard deviation     2.673948e+00 2.655907e+00 2.631559e+00 2.591431e+00\n",
       "Proportion of Variance 2.080630e-06 2.052649e-06 2.015187e-06 1.954197e-06\n",
       "Cumulative Proportion  9.999503e-01 9.999524e-01 9.999544e-01 9.999563e-01\n",
       "                           Comp.589     Comp.590     Comp.591     Comp.592\n",
       "Standard deviation     2.566106e+00 2.505999e+00 2.428558e+00 2.411910e+00\n",
       "Proportion of Variance 1.916189e-06 1.827472e-06 1.716272e-06 1.692821e-06\n",
       "Cumulative Proportion  9.999582e-01 9.999601e-01 9.999618e-01 9.999635e-01\n",
       "                           Comp.593     Comp.594     Comp.595     Comp.596\n",
       "Standard deviation     2.389492e+00 2.352464e+00 2.280938e+00 2.272582e+00\n",
       "Proportion of Variance 1.661499e-06 1.610404e-06 1.513966e-06 1.502893e-06\n",
       "Cumulative Proportion  9.999651e-01 9.999668e-01 9.999683e-01 9.999698e-01\n",
       "                           Comp.597     Comp.598     Comp.599     Comp.600\n",
       "Standard deviation     2.265183e+00 2.236110e+00 2.145478e+00 2.1298987361\n",
       "Proportion of Variance 1.493123e-06 1.455042e-06 1.339482e-06 0.0000013201\n",
       "Cumulative Proportion  9.999713e-01 9.999727e-01 9.999741e-01 0.9999753812\n",
       "                           Comp.601     Comp.602     Comp.603     Comp.604\n",
       "Standard deviation     2.099901e+00 2.065237e+00 2.008649e+00 1.992930e+00\n",
       "Proportion of Variance 1.283178e-06 1.241163e-06 1.174079e-06 1.155774e-06\n",
       "Cumulative Proportion  9.999767e-01 9.999779e-01 9.999791e-01 9.999802e-01\n",
       "                           Comp.605     Comp.606     Comp.607     Comp.608\n",
       "Standard deviation     1.879048e+00 1.867516e+00 1.821209e+00 1.811096e+00\n",
       "Proportion of Variance 1.027459e-06 1.014887e-06 9.651810e-07 9.544910e-07\n",
       "Cumulative Proportion  9.999813e-01 9.999823e-01 9.999832e-01 9.999842e-01\n",
       "                           Comp.609     Comp.610     Comp.611     Comp.612\n",
       "Standard deviation     1.780619e+00 1.775142e+00 1.768467e+00 1.728026e+00\n",
       "Proportion of Variance 9.226379e-07 9.169704e-07 9.100866e-07 8.689398e-07\n",
       "Cumulative Proportion  9.999851e-01 9.999860e-01 9.999869e-01 9.999878e-01\n",
       "                           Comp.613     Comp.614     Comp.615     Comp.616\n",
       "Standard deviation     1.644165e+00 1.614358e+00 1.589678e+00 1.572433e+00\n",
       "Proportion of Variance 7.866465e-07 7.583832e-07 7.353727e-07 7.195041e-07\n",
       "Cumulative Proportion  9.999886e-01 9.999894e-01 9.999901e-01 9.999908e-01\n",
       "                           Comp.617     Comp.618     Comp.619     Comp.620\n",
       "Standard deviation     1.524212e+00 1.491291e+00 1.425147e+00 1.336993e+00\n",
       "Proportion of Variance 6.760515e-07 6.471634e-07 5.910284e-07 5.201727e-07\n",
       "Cumulative Proportion  9.999915e-01 9.999921e-01 9.999927e-01 9.999933e-01\n",
       "                           Comp.621     Comp.622     Comp.623     Comp.624\n",
       "Standard deviation     1.308837e+00 1.294211e+00 1.283259e+00 1.229907e+00\n",
       "Proportion of Variance 4.984942e-07 4.874155e-07 4.792010e-07 4.401831e-07\n",
       "Cumulative Proportion  9.999937e-01 9.999942e-01 9.999947e-01 9.999952e-01\n",
       "                           Comp.625     Comp.626     Comp.627     Comp.628\n",
       "Standard deviation     1.218448e+00 1.181447e+00 1.138542e+00 1.130269e+00\n",
       "Proportion of Variance 4.320191e-07 4.061791e-07 3.772136e-07 3.717518e-07\n",
       "Cumulative Proportion  9.999956e-01 9.999960e-01 9.999964e-01 9.999967e-01\n",
       "                           Comp.629     Comp.630     Comp.631     Comp.632\n",
       "Standard deviation     1.096841e+00 1.060470e+00 9.785780e-01 9.278447e-01\n",
       "Proportion of Variance 3.500875e-07 3.272548e-07 2.786634e-07 2.505184e-07\n",
       "Cumulative Proportion  9.999971e-01 9.999974e-01 9.999977e-01 9.999979e-01\n",
       "                           Comp.633     Comp.634     Comp.635     Comp.636\n",
       "Standard deviation     8.648913e-01 8.548244e-01 7.564052e-01 7.177942e-01\n",
       "Proportion of Variance 2.176768e-07 2.126390e-07 1.664938e-07 1.499301e-07\n",
       "Cumulative Proportion  9.999982e-01 9.999984e-01 9.999985e-01 9.999987e-01\n",
       "                           Comp.637     Comp.638     Comp.639     Comp.640\n",
       "Standard deviation     7.009272e-01 6.980415e-01 6.947212e-01 6.752178e-01\n",
       "Proportion of Variance 1.429667e-07 1.417919e-07 1.404462e-07 1.326712e-07\n",
       "Cumulative Proportion  9.999988e-01 9.999990e-01 9.999991e-01 9.999993e-01\n",
       "                           Comp.641     Comp.642     Comp.643     Comp.644\n",
       "Standard deviation     6.681964e-01 6.402168e-01 5.982622e-01 5.449169e-01\n",
       "Proportion of Variance 1.299264e-07 1.192733e-07 1.041531e-07 8.640713e-08\n",
       "Cumulative Proportion  9.999994e-01 9.999995e-01 9.999996e-01 9.999997e-01\n",
       "                           Comp.645     Comp.646     Comp.647     Comp.648\n",
       "Standard deviation     4.632962e-01 4.454328e-01 4.162388e-01 4.099716e-01\n",
       "Proportion of Variance 6.246065e-08 5.773689e-08 5.041668e-08 4.890987e-08\n",
       "Cumulative Proportion  9.999998e-01 9.999998e-01 9.999999e-01 9.999999e-01\n",
       "                           Comp.649     Comp.650     Comp.651     Comp.652\n",
       "Standard deviation     3.526013e-01 2.090577e-01 2.013877e-01 1.827811e-01\n",
       "Proportion of Variance 3.617903e-08 1.271807e-08 1.180199e-08 9.721909e-09\n",
       "Cumulative Proportion  9.999999e-01 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.653     Comp.654     Comp.655     Comp.656\n",
       "Standard deviation     1.698309e-01 1.055836e-01 1.017268e-01 4.684214e-02\n",
       "Proportion of Variance 8.393102e-09 3.244011e-09 3.011338e-09 6.385022e-10\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.657     Comp.658     Comp.659     Comp.660\n",
       "Standard deviation     4.252223e-02 3.757303e-02 2.213197e-02 6.017515e-03\n",
       "Proportion of Variance 5.261640e-10 4.108104e-10 1.425375e-10 1.053716e-11\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.661     Comp.662     Comp.663     Comp.664\n",
       "Standard deviation     3.613577e-04 1.488320e-05 1.072708e-05 1.011707e-05\n",
       "Proportion of Variance 3.799826e-14 6.445873e-17 3.348516e-17 2.978505e-17\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.665     Comp.666     Comp.667     Comp.668\n",
       "Standard deviation     3.792628e-06 3.773168e-06 3.420088e-06 3.147618e-06\n",
       "Proportion of Variance 4.185714e-18 4.142869e-18 3.403797e-18 2.883056e-18\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.669     Comp.670     Comp.671     Comp.672\n",
       "Standard deviation     2.899155e-06 2.146688e-06 1.813482e-06 1.779657e-06\n",
       "Proportion of Variance 2.445862e-18 1.340994e-18 9.570076e-19 9.216408e-19\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.673     Comp.674     Comp.675     Comp.676\n",
       "Standard deviation     1.753359e-06 1.746011e-06 1.724704e-06 1.692617e-06\n",
       "Proportion of Variance 8.946033e-19 8.871217e-19 8.656024e-19 8.336938e-19\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.677     Comp.678     Comp.679     Comp.680\n",
       "Standard deviation     1.671181e-06 1.637266e-06 1.584305e-06 1.343866e-06\n",
       "Proportion of Variance 8.127104e-19 7.800587e-19 7.304097e-19 5.255341e-19\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.681     Comp.682     Comp.683     Comp.684\n",
       "Standard deviation     1.074509e-06 7.010015e-07 5.881254e-07 3.359897e-07\n",
       "Proportion of Variance 3.359765e-19 1.429970e-19 1.006535e-19 3.285043e-20\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.685     Comp.686     Comp.687     Comp.688\n",
       "Standard deviation     3.329180e-07 3.146039e-07 2.964748e-07 2.918227e-07\n",
       "Proportion of Variance 3.225252e-20 2.880164e-20 2.557789e-20 2.478148e-20\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.689     Comp.690     Comp.691     Comp.692\n",
       "Standard deviation     2.743177e-07 2.706099e-07 2.365553e-07 2.330530e-07\n",
       "Proportion of Variance 2.189760e-20 2.130966e-20 1.628374e-20 1.580514e-20\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.693     Comp.694     Comp.695     Comp.696\n",
       "Standard deviation     7.152448e-08 4.471476e-08 2.719202e-08 6.348901e-14\n",
       "Proportion of Variance 1.488670e-21 5.818230e-22 2.151652e-22 1.172968e-33\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.697     Comp.698     Comp.699     Comp.700\n",
       "Standard deviation     3.643286e-14 6.618452e-15 4.438724e-15 4.117216e-15\n",
       "Proportion of Variance 3.862562e-34 1.274682e-35 5.733310e-36 4.932832e-36\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.701     Comp.702     Comp.703     Comp.704\n",
       "Standard deviation     3.362205e-15 2.438021e-15 2.958609e-22 2.430699e-22\n",
       "Proportion of Variance 3.289558e-36 1.729673e-36 2.547207e-50 1.719299e-50\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                           Comp.705     Comp.706     Comp.707     Comp.708\n",
       "Standard deviation     2.131930e-22 1.866867e-22 3.506084e-30 3.169986e-30\n",
       "Proportion of Variance 1.322619e-50 1.014182e-50 3.577122e-66 2.924178e-66\n",
       "Cumulative Proportion  1.000000e+00 1.000000e+00 1.000000e+00 1.000000e+00\n",
       "                       Comp.709 Comp.710 Comp.711 Comp.712 Comp.713 Comp.714\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.715 Comp.716 Comp.717 Comp.718 Comp.719 Comp.720\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.721 Comp.722 Comp.723 Comp.724 Comp.725 Comp.726\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.727 Comp.728 Comp.729 Comp.730 Comp.731 Comp.732\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.733 Comp.734 Comp.735 Comp.736 Comp.737 Comp.738\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.739 Comp.740 Comp.741 Comp.742 Comp.743 Comp.744\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.745 Comp.746 Comp.747 Comp.748 Comp.749 Comp.750\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.751 Comp.752 Comp.753 Comp.754 Comp.755 Comp.756\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.757 Comp.758 Comp.759 Comp.760 Comp.761 Comp.762\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.763 Comp.764 Comp.765 Comp.766 Comp.767 Comp.768\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.769 Comp.770 Comp.771 Comp.772 Comp.773 Comp.774\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.775 Comp.776 Comp.777 Comp.778 Comp.779 Comp.780\n",
       "Standard deviation            0        0        0        0        0        0\n",
       "Proportion of Variance        0        0        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1        1        1\n",
       "                       Comp.781 Comp.782 Comp.783 Comp.784\n",
       "Standard deviation            0        0        0        0\n",
       "Proportion of Variance        0        0        0        0\n",
       "Cumulative Proportion         1        1        1        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_results <- princomp(x_train, cor = F)\n",
    "summary(pca_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick the final dimension to be $9$. This is a trade-off between training time and (possibly) prediction accuracy. \n",
    "\n",
    "With this dimension, each training costs around $5\\,\\mathrm{s}$ on my machine. Note that this number will be multiplied by $5$ for 5-fold CV, and another factor of around $10$ for hyperparameter search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_projections <- as.data.frame(x_train %*% loadings(pca_results)[, 1:9])\n",
    "pca_projections_test <- as.data.frame(x_test %*% loadings(pca_results)[, 1:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat <- pca_projections\n",
    "dat['y'] <- as.factor(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With traning data saved in ``dat``, we are ready to do SVM training. The training will be in the order of linear, radial, and polynomial kernels.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I will first focus on the training of SVM itself and then show the result of different kernels side by side.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We directly use $5$-fold CV to choose the best model over ``cost``. The best shot occurs at ``cost=1`` in our case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of ‘svm’:\n",
       "\n",
       "- sampling method: 5-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " cost\n",
       "    1\n",
       "\n",
       "- best performance: 0.1615 \n",
       "\n",
       "- Detailed performance results:\n",
       "   cost  error  dispersion\n",
       "1  0.01 0.1727 0.005663479\n",
       "2  0.10 0.1642 0.005251190\n",
       "3  1.00 0.1615 0.004568917\n",
       "4  5.00 0.1619 0.004052777\n",
       "5 10.00 0.1625 0.005431390\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune.out <- tune(\n",
    "    svm, y ~ .,\n",
    "    data = dat, kernel = \"linear\",\n",
    "    ranges = list(cost = c(0.01, 0.1, 1, 5, 10)),\n",
    "    tunecontrol = tune.control(sampling = \"cross\", cross = 5)\n",
    ")\n",
    "summary(tune.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit_linear <- svm(y ~ ., data = dat, kernel = \"linear\", cost = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of ‘svm’:\n",
       "\n",
       "- sampling method: 5-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " cost gamma\n",
       "    5   0.2\n",
       "\n",
       "- best performance: 0.0829 \n",
       "\n",
       "- Detailed performance results:\n",
       "  cost gamma  error  dispersion\n",
       "1  0.1   0.2 0.1174 0.003507136\n",
       "2  1.0   0.2 0.0858 0.003581201\n",
       "3  5.0   0.2 0.0829 0.004292435\n",
       "4  0.1   1.0 0.3209 0.036705585\n",
       "5  1.0   1.0 0.0942 0.004957318\n",
       "6  5.0   1.0 0.0978 0.007285259\n",
       "7  0.1   5.0 0.8181 0.011414903\n",
       "8  1.0   5.0 0.5021 0.054820617\n",
       "9  5.0   5.0 0.4651 0.051705174\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune.out <- tune(\n",
    "    svm, y ~ .,\n",
    "    data = dat, kernel = \"radial\",\n",
    "    ranges = list(cost = c(0.1, 1, 5), gamma = c(0.2, 1, 5)), \n",
    "    tunecontrol = tune.control(sampling = \"cross\", cross = 5)\n",
    ")\n",
    "summary(tune.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit_radial <- svm(y ~ ., data = dat, kernel = \"radial\", cost = 5, gamma = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "svm(formula = y ~ ., data = dat, kernel = \"polynomial\", cost = 1, \n",
       "    degree = 3, gamma = 0.3)\n",
       "\n",
       "\n",
       "Parameters:\n",
       "   SVM-Type:  C-classification \n",
       " SVM-Kernel:  polynomial \n",
       "       cost:  1 \n",
       "     degree:  3 \n",
       "     coef.0:  0 \n",
       "\n",
       "Number of Support Vectors:  2632\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm(y ~ ., data=dat, kernel='polynomial', cost = 5, degree=3, gamma=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of ‘svm’:\n",
       "\n",
       "- sampling method: 5-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " degree\n",
       "      3\n",
       "\n",
       "- best performance: 0.102 \n",
       "\n",
       "- Detailed performance results:\n",
       "  degree  error  dispersion\n",
       "1      1 0.1626 0.007074602\n",
       "2      2 0.1696 0.008981926\n",
       "3      3 0.1020 0.008455767\n",
       "4      4 0.1688 0.007496666\n",
       "5      5 0.1199 0.006377696\n",
       "6      6 0.2020 0.004650269\n",
       "7      7 0.1434 0.008317151\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune.out <- tune(\n",
    "    svm, y ~ .,\n",
    "    data = dat, kernel = \"polynomial\",\n",
    "    cost = 5, \n",
    "    gamma = .2,\n",
    "    ranges = list(degree=1:7), \n",
    "    tunecontrol = tune.control(sampling = \"cross\", cross = 5)\n",
    ")\n",
    "summary(tune.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of ‘svm’:\n",
       "\n",
       "- sampling method: 5-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " cost\n",
       "    1\n",
       "\n",
       "- best performance: 0.0983 \n",
       "\n",
       "- Detailed performance results:\n",
       "  cost  error  dispersion\n",
       "1  0.1 0.1095 0.005326819\n",
       "2  1.0 0.0983 0.004309872\n",
       "3  5.0 0.1041 0.004083503\n",
       "4 10.0 0.1075 0.004000000\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune.out <- tune(\n",
    "    svm, y ~ .,\n",
    "    data = dat, kernel = \"polynomial\",\n",
    "    gamma = .2,\n",
    "    degree = 3,\n",
    "    ranges = list(cost=c(.1, 1, 5, 10)), \n",
    "    tunecontrol = tune.control(sampling = \"cross\", cross = 5)\n",
    ")\n",
    "summary(tune.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Parameter tuning of ‘svm’:\n",
       "\n",
       "- sampling method: 5-fold cross validation \n",
       "\n",
       "- best parameters:\n",
       " gamma\n",
       "   0.2\n",
       "\n",
       "- best performance: 0.0999 \n",
       "\n",
       "- Detailed performance results:\n",
       "  gamma  error  dispersion\n",
       "1   0.2 0.0999 0.006730527\n",
       "2   0.5 0.1076 0.010899541\n",
       "3   1.0 0.1232 0.011421471\n",
       "4   2.0 0.1296 0.007700649\n",
       "5   4.0 0.1322 0.009162423\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tune.out <- tune(\n",
    "    svm, y ~ .,\n",
    "    data = dat, kernel = \"polynomial\",\n",
    "    degree = 3,\n",
    "    cost = 1,\n",
    "    ranges = list(gamma = c(.2, .5, 1, 2, 4)),\n",
    "    tunecontrol = tune.control(sampling = \"cross\", cross = 5)\n",
    ")\n",
    "summary(tune.out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmfit_polynomial <- svm(\n",
    "    y ~ .,\n",
    "    data = dat, kernel = \"polynomial\", cost = 5, gamma = .2, degree = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lin <- predict(svmfit_linear, pca_projections_test)\n",
    "y_pred_rad <- predict(svmfit_radial, pca_projections_test)\n",
    "y_pred_poly <- predict(svmfit_polynomial, pca_projections_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>linear</dt><dd>0.823383333333333</dd><dt>radial</dt><dd>0.906966666666667</dd><dt>polynomial</dt><dd>0.88515</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[linear] 0.823383333333333\n",
       "\\item[radial] 0.906966666666667\n",
       "\\item[polynomial] 0.88515\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "linear\n",
       ":   0.823383333333333radial\n",
       ":   0.906966666666667polynomial\n",
       ":   0.88515\n",
       "\n"
      ],
      "text/plain": [
       "    linear     radial polynomial \n",
       " 0.8233833  0.9069667  0.8851500 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c(\n",
    "    linear = mean(y_pred_lin == y_test),\n",
    "    radial = mean(y_pred_rad == y_test),\n",
    "    polynomial = mean(y_pred_poly == y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tensorflow)\n",
    "library(keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in system(\"timedatectl\", intern = TRUE):\n",
      "“running command 'timedatectl' had status 1”\n",
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.5     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.4     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.7\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.0.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ``Keras`` is capable of handling matrix input. We convert the data type back to matrix by just reloading the data file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "load(\"mnist.RData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I use $5$-fold CV to find out the best hyperparameter of ``epochs`` and ``batch_size``. The max epoch is set to $10$ (the default value) in compliance with the early-stopping strategy. \n",
    "\n",
    "One interesting point to note in the computation is that the larger the ``batch_size``, the quicker NN trains. \n",
    "\n",
    "In order to save time finding out how to properly reset a model in ``Keras``, I just copy-and-paste the code $5$ times to simulate the $5$-fold CV needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size $32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_index <- c(1:2000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc1 <- metrics$val_accuracy\n",
    "\n",
    "\n",
    "validation_index <- c(2000:4000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc2 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(4000:6000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc3 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(6000:8000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc4 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(8000:10000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc5 <- metrics$val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.855156064033508</li><li>0.881046676635742</li><li>0.896440029144287</li><li>0.905335581302643</li><li>0.905137228965759</li><li>0.914532887935638</li><li>0.910533785820007</li><li>0.911633431911469</li><li>0.915231871604919</li><li>0.913730442523956</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.855156064033508\n",
       "\\item 0.881046676635742\n",
       "\\item 0.896440029144287\n",
       "\\item 0.905335581302643\n",
       "\\item 0.905137228965759\n",
       "\\item 0.914532887935638\n",
       "\\item 0.910533785820007\n",
       "\\item 0.911633431911469\n",
       "\\item 0.915231871604919\n",
       "\\item 0.913730442523956\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.855156064033508\n",
       "2. 0.881046676635742\n",
       "3. 0.896440029144287\n",
       "4. 0.905335581302643\n",
       "5. 0.905137228965759\n",
       "6. 0.914532887935638\n",
       "7. 0.910533785820007\n",
       "8. 0.911633431911469\n",
       "9. 0.915231871604919\n",
       "10. 0.913730442523956\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.8551561 0.8810467 0.8964400 0.9053356 0.9051372 0.9145329 0.9105338\n",
       " [8] 0.9116334 0.9152319 0.9137304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowMeans(cbind(valid_acc1, valid_acc2, valid_acc3, valid_acc4, valid_acc5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size $16$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_index <- c(1:2000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=16,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc1 <- metrics$val_accuracy\n",
    "\n",
    "\n",
    "validation_index <- c(2000:4000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=16,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc2 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(4000:6000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=16,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc3 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(6000:8000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=16,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc4 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(8000:10000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=16,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc5 <- metrics$val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.857955169677734</li><li>0.867352426052094</li><li>0.886645472049713</li><li>0.893242824077606</li><li>0.906136178970337</li><li>0.904937434196472</li><li>0.899439632892609</li><li>0.895142734050751</li><li>0.910835123062134</li><li>0.899539434909821</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.857955169677734\n",
       "\\item 0.867352426052094\n",
       "\\item 0.886645472049713\n",
       "\\item 0.893242824077606\n",
       "\\item 0.906136178970337\n",
       "\\item 0.904937434196472\n",
       "\\item 0.899439632892609\n",
       "\\item 0.895142734050751\n",
       "\\item 0.910835123062134\n",
       "\\item 0.899539434909821\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.857955169677734\n",
       "2. 0.867352426052094\n",
       "3. 0.886645472049713\n",
       "4. 0.893242824077606\n",
       "5. 0.906136178970337\n",
       "6. 0.904937434196472\n",
       "7. 0.899439632892609\n",
       "8. 0.895142734050751\n",
       "9. 0.910835123062134\n",
       "10. 0.899539434909821\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.8579552 0.8673524 0.8866455 0.8932428 0.9061362 0.9049374 0.8994396\n",
       " [8] 0.8951427 0.9108351 0.8995394"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowMeans(cbind(valid_acc1, valid_acc2, valid_acc3, valid_acc4, valid_acc5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size $64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_index <- c(1:2000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc1 <- metrics$val_accuracy\n",
    "\n",
    "\n",
    "validation_index <- c(2000:4000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc2 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(4000:6000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc3 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(6000:8000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc4 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(8000:10000)\n",
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "metrics <- (model_mlp %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc5 <- metrics$val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.860650765895844</li><li>0.883844017982483</li><li>0.895039641857147</li><li>0.904635679721832</li><li>0.912732446193695</li><li>0.908034193515778</li><li>0.914132916927338</li><li>0.918230390548706</li><li>0.924528741836548</li><li>0.922329533100128</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.860650765895844\n",
       "\\item 0.883844017982483\n",
       "\\item 0.895039641857147\n",
       "\\item 0.904635679721832\n",
       "\\item 0.912732446193695\n",
       "\\item 0.908034193515778\n",
       "\\item 0.914132916927338\n",
       "\\item 0.918230390548706\n",
       "\\item 0.924528741836548\n",
       "\\item 0.922329533100128\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.860650765895844\n",
       "2. 0.883844017982483\n",
       "3. 0.895039641857147\n",
       "4. 0.904635679721832\n",
       "5. 0.912732446193695\n",
       "6. 0.908034193515778\n",
       "7. 0.914132916927338\n",
       "8. 0.918230390548706\n",
       "9. 0.924528741836548\n",
       "10. 0.922329533100128\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.8606508 0.8838440 0.8950396 0.9046357 0.9127324 0.9080342 0.9141329\n",
       " [8] 0.9182304 0.9245287 0.9223295"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowMeans(cbind(valid_acc1, valid_acc2, valid_acc3, valid_acc4, valid_acc5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly $5$-fold CV reveals that ``epochs=9`` and ``batch_size=64`` would be a good hyperparameter. The accuracy on test data is $91.1\\%$, better than the radial-kernel SVM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.921334 \n",
      "Test accuracy: 0.9113 \n"
     ]
    }
   ],
   "source": [
    "model_mlp <- keras_model_sequential()\n",
    "model_mlp %>%\n",
    "    layer_flatten(input_shape = c(28, 28)) %>%\n",
    "    layer_dense(units = 128, activation = \"relu\") %>%\n",
    "    layer_dense(units = 10, activation = \"softmax\")\n",
    "model_mlp %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "model_mlp %>% fit(x_train, y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 9,\n",
    "    validation_split = .2\n",
    ")\n",
    "score <- model_mlp %>% evaluate(x_test, y_test)\n",
    "\n",
    "cat(\"Test loss:\", score[1], \"\\n\")\n",
    "cat(\"Test accuracy:\", score[2], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.cnn <- array(x_train, dim = c(dim(x_train)[1], dim(x_train)[2], dim(x_train)[3], 1))\n",
    "x_test.cnn <- array(x_test, dim = c(dim(x_test)[1], dim(x_test)[2], dim(x_test)[3], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size $32$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_index <- c(1:2000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc1 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(2000:4000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc2 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(4000:6000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc3 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(6000:8000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc4 <- metrics$val_accuracy\n",
    "\n",
    "\n",
    "validation_index <- c(8000:10000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=32,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc5 <- metrics$val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.680694103240967</li><li>0.817533838748932</li><li>0.893621504306793</li><li>0.930618894100189</li><li>0.949514138698578</li><li>0.956714189052582</li><li>0.961712980270386</li><li>0.964612400531769</li><li>0.97091019153595</li><li>0.969710445404053</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.680694103240967\n",
       "\\item 0.817533838748932\n",
       "\\item 0.893621504306793\n",
       "\\item 0.930618894100189\n",
       "\\item 0.949514138698578\n",
       "\\item 0.956714189052582\n",
       "\\item 0.961712980270386\n",
       "\\item 0.964612400531769\n",
       "\\item 0.97091019153595\n",
       "\\item 0.969710445404053\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.680694103240967\n",
       "2. 0.817533838748932\n",
       "3. 0.893621504306793\n",
       "4. 0.930618894100189\n",
       "5. 0.949514138698578\n",
       "6. 0.956714189052582\n",
       "7. 0.961712980270386\n",
       "8. 0.964612400531769\n",
       "9. 0.97091019153595\n",
       "10. 0.969710445404053\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.6806941 0.8175338 0.8936215 0.9306189 0.9495141 0.9567142 0.9617130\n",
       " [8] 0.9646124 0.9709102 0.9697104"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowMeans(cbind(valid_acc1, valid_acc2, valid_acc3, valid_acc4, valid_acc5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size $64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_index <- c(1:2000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc1 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(2000:4000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc2 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(4000:6000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc3 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(6000:8000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc4 <- metrics$val_accuracy\n",
    "\n",
    "\n",
    "validation_index <- c(8000:10000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=64,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc5 <- metrics$val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.554376769065857</li><li>0.784488117694855</li><li>0.8954385638237</li><li>0.93722288608551</li><li>0.950018298625946</li><li>0.958115351200104</li><li>0.960114550590515</li><li>0.962514448165894</li><li>0.966912543773651</li><li>0.966812002658844</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.554376769065857\n",
       "\\item 0.784488117694855\n",
       "\\item 0.8954385638237\n",
       "\\item 0.93722288608551\n",
       "\\item 0.950018298625946\n",
       "\\item 0.958115351200104\n",
       "\\item 0.960114550590515\n",
       "\\item 0.962514448165894\n",
       "\\item 0.966912543773651\n",
       "\\item 0.966812002658844\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.554376769065857\n",
       "2. 0.784488117694855\n",
       "3. 0.8954385638237\n",
       "4. 0.93722288608551\n",
       "5. 0.950018298625946\n",
       "6. 0.958115351200104\n",
       "7. 0.960114550590515\n",
       "8. 0.962514448165894\n",
       "9. 0.966912543773651\n",
       "10. 0.966812002658844\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.5543768 0.7844881 0.8954386 0.9372229 0.9500183 0.9581154 0.9601146\n",
       " [8] 0.9625144 0.9669125 0.9668120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowMeans(cbind(valid_acc1, valid_acc2, valid_acc3, valid_acc4, valid_acc5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size $128$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_index <- c(1:2000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=128,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc1 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(2000:4000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=128,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc2 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(4000:6000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=128,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc3 <- metrics$val_accuracy\n",
    "\n",
    "validation_index <- c(6000:8000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=128,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc4 <- metrics$val_accuracy\n",
    "\n",
    "\n",
    "validation_index <- c(8000:10000)\n",
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "  optimizer = 'adam', \n",
    "  loss = 'sparse_categorical_crossentropy',\n",
    "  metrics = c('accuracy')\n",
    ")\n",
    "metrics <- (model.cnn %>% fit(x_train[-validation_index,,], y_train[-validation_index],\n",
    "    batch_size=128,\n",
    "    validation_data=list(x_train[validation_index,,], y_train[validation_index])\n",
    "))$metrics\n",
    "valid_acc5 <- metrics$val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.391658574342728</li><li>0.65505211353302</li><li>0.788393700122833</li><li>0.863358974456787</li><li>0.918933141231537</li><li>0.933825576305389</li><li>0.946920382976532</li><li>0.952918136119843</li><li>0.958815884590149</li><li>0.961114799976349</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.391658574342728\n",
       "\\item 0.65505211353302\n",
       "\\item 0.788393700122833\n",
       "\\item 0.863358974456787\n",
       "\\item 0.918933141231537\n",
       "\\item 0.933825576305389\n",
       "\\item 0.946920382976532\n",
       "\\item 0.952918136119843\n",
       "\\item 0.958815884590149\n",
       "\\item 0.961114799976349\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.391658574342728\n",
       "2. 0.65505211353302\n",
       "3. 0.788393700122833\n",
       "4. 0.863358974456787\n",
       "5. 0.918933141231537\n",
       "6. 0.933825576305389\n",
       "7. 0.946920382976532\n",
       "8. 0.952918136119843\n",
       "9. 0.958815884590149\n",
       "10. 0.961114799976349\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 0.3916586 0.6550521 0.7883937 0.8633590 0.9189331 0.9338256 0.9469204\n",
       " [8] 0.9529181 0.9588159 0.9611148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowMeans(cbind(valid_acc1, valid_acc2, valid_acc3, valid_acc4, valid_acc5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the best accuracy occurs at ``batch_size=32`` and ``epochs=9``. Although training CNN is more time-consuming, an accuracy of $96.2\\%$ makes it worthwhile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1349014 \n",
      "Test accuracy: 0.9622333 \n"
     ]
    }
   ],
   "source": [
    "model.cnn <- keras_model_sequential()\n",
    "# configuring the Model\n",
    "model.cnn %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3), padding = \"same\", input_shape = c(28, 28, 1)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_conv_2d(filter = 32, kernel_size = c(3, 3)) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_max_pooling_2d(pool_size = c(2, 2)) %>%\n",
    "    layer_dropout(0.25) %>%\n",
    "    layer_flatten() %>%\n",
    "    layer_dense(64) %>%\n",
    "    layer_activation(\"relu\") %>%\n",
    "    layer_dropout(0.5) %>%\n",
    "    layer_dense(10) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "model.cnn %>% compile(\n",
    "    optimizer = \"adam\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = c(\"accuracy\")\n",
    ")\n",
    "model.cnn %>% fit(x_train[-validation_index, , ], y_train[-validation_index],\n",
    "    batch_size = 32,\n",
    "    validation_split = 0.2,\n",
    "    epochs = 9\n",
    ")\n",
    "score <- model.cnn %>% evaluate(x_test, y_test)\n",
    "\n",
    "cat(\"Test loss:\", score[1], \"\\n\")\n",
    "cat(\"Test accuracy:\", score[2], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up, I would like to resummarise the results into the following table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>method</th><th scope=col>best.accuracy</th><th scope=col>optimized.parameter</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>Linear SVM    </td><td>0.823</td><td>cost=1                     </td></tr>\n",
       "\t<tr><td>Radial SVM    </td><td>0.907</td><td>cost=5, gamma=0.2          </td></tr>\n",
       "\t<tr><td>Polynomial SVM</td><td>0.885</td><td>cost=1, gamma=0.2, degree=3</td></tr>\n",
       "\t<tr><td>MLP           </td><td>0.911</td><td>batch size=64, epochs=9    </td></tr>\n",
       "\t<tr><td>CNN           </td><td>0.962</td><td>batch size=32, epochs=9    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 3\n",
       "\\begin{tabular}{lll}\n",
       " method & best.accuracy & optimized.parameter\\\\\n",
       " <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t Linear SVM     & 0.823 & cost=1                     \\\\\n",
       "\t Radial SVM     & 0.907 & cost=5, gamma=0.2          \\\\\n",
       "\t Polynomial SVM & 0.885 & cost=1, gamma=0.2, degree=3\\\\\n",
       "\t MLP            & 0.911 & batch size=64, epochs=9    \\\\\n",
       "\t CNN            & 0.962 & batch size=32, epochs=9    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 3\n",
       "\n",
       "| method &lt;chr&gt; | best.accuracy &lt;dbl&gt; | optimized.parameter &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| Linear SVM     | 0.823 | cost=1                      |\n",
       "| Radial SVM     | 0.907 | cost=5, gamma=0.2           |\n",
       "| Polynomial SVM | 0.885 | cost=1, gamma=0.2, degree=3 |\n",
       "| MLP            | 0.911 | batch size=64, epochs=9     |\n",
       "| CNN            | 0.962 | batch size=32, epochs=9     |\n",
       "\n"
      ],
      "text/plain": [
       "  method         best.accuracy optimized.parameter        \n",
       "1 Linear SVM     0.823         cost=1                     \n",
       "2 Radial SVM     0.907         cost=5, gamma=0.2          \n",
       "3 Polynomial SVM 0.885         cost=1, gamma=0.2, degree=3\n",
       "4 MLP            0.911         batch size=64, epochs=9    \n",
       "5 CNN            0.962         batch size=32, epochs=9    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.frame(\n",
    "    method = c(\"Linear SVM\", \"Radial SVM\", \"Polynomial SVM\", \"MLP\", \"CNN\"),\n",
    "    best.accuracy = c(0.823, .907, .885, .911, .962),\n",
    "    optimized.parameter = c(\"cost=1\", \"cost=5, gamma=0.2\", \"cost=1, gamma=0.2, degree=3\", \"batch size=64, epochs=9\", \"batch size=32, epochs=9\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
